---
title: "Second model run"
output: html_notebook
---

Good talk! So my action items are:

* Drop points that are impossible habitat (ie, ranked less than 0 = water)
* Rescale variables.
* Check out some interactions between HSI & other variables.
* Reduce dataset to some lowest common denominator of data.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Load some libraries.
library('ggplot2')
library('tidyverse')
library('lme4')

# Read in the points.
points <- read.csv('../data/interim/points.csv', stringsAsFactors=FALSE)

p.points <- points %>%
  filter(n_hab >= 0)

ggplot(p.points, aes(x=cover, y=n_hab, fill=density)) +
  theme_classic() +
  geom_boxplot()
```

This tells me I have a problem with my cover and density categories. I need to find a better way to handle the difference categories and how they intercept. Let's start by looking at some of the oddities.

```{r echo=TRUE, message=FALSE, warning=FALSE}
p.points %>% filter(cover=='')
```

`LA` means lake, so this should have been tossed with other water points. It's impossible to know from looking it it whether the `density` is wrong or the `n_hab` is wrong, but I'll drop it to be safe.

```{r echo=TRUE, message=FALSE, warning=FALSE}
p.points <- p.points %>% filter(!cover=='')
```

That leaves `RZ` and `UR` as oddities, which are "road surface" and "urban". I think I can collapse those into a single category, say `NL` for "nil."

```{r echo=TRUE, message=FALSE, warning=FALSE}
p.points <- p.points %>% mutate(density=case_when(
  density=='RZ' ~ 'NL',
  density=='UR' ~ 'NL',
  TRUE ~ density
))

# And then scale the numeric variables.
s.points <- p.points %>% mutate(canopy.closure=scale(canopy.closure), basal.area=scale(basal.area), live.stems=scale(live.stems), v.comp=scale(v.comp), dom.sp.per=scale(dom.sp.per), age=scale(age), height=scale(height))
```

So now that I've scaled things, I can try running the model again just so see if I get the same error.

```{r echo=TRUE, message=FALSE, warning=FALSE}
sink.corr <- glmer(case ~ canopy.closure + basal.area + density + (1|site), data=s.points, family=binomial(link='logit'))
```

Woohoo! No error messages. So the rescaling thing worked like a charm. Now to figure out my max dataset situation.

```{r echo=TRUE, message=FALSE, warning=FALSE}
map(p.points, ~sum(is.na(.)))
```

Part of the problem is that many of these cover classes don't include the variables I'm interested in, since they're mostly forest-related. So obviously shrub points don't have a value for vertical complexity. For example: 

```{r echo=TRUE, message=FALSE, warning=FALSE}
p.points[which(is.na(p.points$live.stems)), ]
```

This means either I'm very limited in the questions I can ask, or I have to fill in some of those missing values with something interesting. If I drop the missing values, this means I need to restrict myself to forested points, so I can ask:

*out of all the forest available, what best predicts the kind of forest where NOGO choose to roost?*

If I fill in as many missing values as I reasonably can, then I can ask a broader question:

*out of all the land available, what best predicts the kind of land where NOGO choose to roost?*

The second question feels better, but since I already know they're only roosting in forest anyway, does dropping non-forested points make any less sense than dropping water points?

Well, the obvious answer is to cheat and run it both ways. But looking closer at the data I feel like I'm not confident in interpreting some of these numbers outside the category of forest. Yes, it makes sense that a shrub point doesn't have any data for basal area, but what does it mean when the points has 16% crown closure?? Or 1000 live stems/ha?? So maybe it would be better to stick to the tree points.

```{r echo=TRUE, message=FALSE, warning=FALSE}
f.points <- s.points %>% filter(cover %in% c('TC', 'TM', 'TB')) %>%
  drop_na()

f.points %>% group_by(case) %>%
  summarize(n())
```

That gives me a much smaller dataset (there were still about 80 points without vertical complexity). Hopefully that will be enough! Then from here I can make some plausible candidate models. One set, obviously, is just the HSI.

* case ~ n_hab
* case ~ f_hab

Then I can add some things that might be help boost the HSI. A study on NOGO roosting in Lassen, CA found basal area was a good predictor. Tree species was also a good predictor, but this is included in the HSI already. Canopy closure is obvious, as is vertical complexity.

* case ~ n_hab + basal.area
* case ~ n_hab + canopy.closure
* case ~ n_hab + v.comp

Unless f_hab does really good on it's own, I don't think I'll bother "bosting" it. I can also try these variables on their own.

* case ~ basal.area
* case ~ canopy.closure
* case ~ v.comp

```{r echo=TRUE, message=FALSE, warning=FALSE}
# "Boost" models.
b.basal <- glmer(case ~ n_hab + basal.area + (1|site), data=f.points, family=binomial(link='logit'))

b.canopy <- glmer(case ~ n_hab + canopy.closure + (1|site), data=f.points, family=binomial(link='logit'))

b.comp <- glmer(case ~ n_hab + v.comp + (1|site), data=f.points, family=binomial(link='logit'))

# "Solo" models.
s.basal <- glmer(case ~ basal.area + (1|site), data=f.points, family=binomial(link='logit'))

s.canopy <- glmer(case ~ canopy.closure + (1|site), data=f.points, family=binomial(link='logit'))

s.comp <- glmer(case ~ v.comp + (1|site), data=f.points, family=binomial(link='logit'))

# And of course habitat models.
n.hab <- glmer(case ~ n_hab + (1|site), data=f.points, family=binomial(link='logit'))

f.hab <- glmer(case ~ f_hab + (1|site), data=f.points, family=binomial(link='logit'))

# Check what pops out.
aic <- AIC(b.basal, b.canopy, b.comp, s.basal, s.canopy, s.comp, n.hab, f.hab)

aic %>% rownames_to_column() %>%
  arrange(AIC)
```

So unsurprisingly, adding canopy cover was an improvement over nesting habitat alone. What was surprising was that canopy cover, all on its own, is *still* better than the nesting habitat model. Also, distance from edge is included in the n_hsi and could conceivably be dragging it down... would be interesting to test canopy closure + f_hab.

The only potential problem I can see here is that canopy cover may not be evenly distributed among my points. That is, by dropping points without canopy cover I somehow biased my data. I'll have to check that next.